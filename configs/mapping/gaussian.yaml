warmup: 10 # Wait until tracking gets to this frame
delay: 3 # Delay between tracking and mapping
mapping_iters: 15 # Optimization iterations for selected views
refinement_iters: 50 # Final Optimization iterations for all views
use_non_keyframes: True # Use non-keyframes during map refinement
max_frames_refinement: 100 # Maximum number of frames to optimize during refinement

batch_mode: False # Only update a constant sized batch of frames
save_renders: False

filter_multiview: False
filter_uncertainty: True 

# use these two flags to snychronize the updated map and poses back into the SLAM system
feedback_mapping: True
optimize_poses: True
 
# Strategy for adding / pruning Gaussians
keyframes:
  n_last_frames: 15 # Always optimize the last n frames
  n_rand_frames: 5 # Optimize random global frames on top
  default_batch_size: 3 # Only add 5 frames at once to increase latency when batch_mode is deactivated
  prune_every: 10 # How often to prune gaussians during mapping refinement

  prune_mode: "new" # "abs" or "new" for absolute or recent pruning

  visibility_th: 2 # Gaussians not visible by visibility_th other frames are pruned
  prune_last: 3 # Gaussians added in the last prune_last are pruned

  abs_visibility_th: 2 # Remove gaussians that are not seen by at least this many other frames

  filter: # Parameter for filtering incoming points from the SLAM system
    mv_count_thresh: 2 # Pixels need to be consistent within bin_thresh distance across these k views
    bin_thresh: 0.1
    confidence_thresh: 0.1 # Only take pixels above this confidence

  mapping:
    densify_grad_threshold: 0.00001
    size_threshold: 20
    opacity_th: 0.01
    gaussian_extent: 5

  refinement:
    densify_grad_threshold: 0.0002
    size_threshold: 10
    opacity_th: 0.05
    gaussian_extent: 2

opt_params:
  init_lr: 6.0
  position_lr_init: 0.00016
  position_lr_final: 0.0000016
  position_lr_delay_mult: 0.01
  position_lr_max_steps: 200
  feature_lr: 0.0025
  opacity_lr: 0.05
  scaling_lr: 0.001
  rotation_lr: 0.001
  percent_dense: 0.01

  # LR for pose optimization
  # NOTE you have to watch out here in case of big map changes, this can break
  # we sample random poses, so not moving too much from the tracking poses is smart
  cam_rot_delta: 0.0003 # 0.0003
  cam_trans_delta: 0.0001 # 0.0001

loss:
  # Decide which loss terms to use
  with_edge_weight: True # Weight informative pixels with high image gradient higher in loss
  use_ssim: True # Use SSIM on top of L1 loss
  use_depth_smoothness_reg: True # Similarity loss between depth and image gradients

  rgb_boundary_threshold: 0.01 # Pixel information in an image needs to be at least higher than this 
  ### Loss weights
  alpha1: 0.75 # Size of the mapping loss that the rgb takes up, the rest is depth (default: 0.95)
  alpha2: 0.85 # Weight SSIM and L1 loss (default 0.85 is common in monocular depth estimation)
  beta: 5.0 # Regularizer on scale changes of the Gaussians
  beta2: 0.001 # Edge-aware smoothness loss for depth (default 0.001 is common in monocular depth estimation)

# Parameters for transfer SLAM -> Renderer
input:
  sensor_type: 'depth'
  pcd_downsample_init: 16
  pcd_downsample: 32
  adaptive_pointsize: False
  point_size: 0.05
  type: 'replica'

use_spherical_harmonics: False
pipeline_params:
  convert_SHs_python: False
  compute_cov3D_python: False