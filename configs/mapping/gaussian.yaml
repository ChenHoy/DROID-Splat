warmup: 12 # Wait until tracking gets to this frame
delay: 2 # Delay between tracking and mapping
use_non_keyframes: True # Use non-keyframes during map refinement
max_frames_refinement: 80 # Maximum number of frames to optimize during refinement
use_prior_for_supervision: True # Use the prior for supervision. If not, then use the current filtered map from SLAM

# NOTE chen: please use MORE ITERATIONS than prune_densify_every! 
# it is important to optimize newly introduced Gaussians due to densification!!!
mapping_iters: 15 # Optimization iterations for selected views
refinement_iters: 50 # Final Optimization iterations for all views
# These 2 flags filter out noisy points before Rendering Optimization
filter_multiview: True # Only initialize Gaussians that are consistent in multiple views
filter_uncertainty: True # Only use very certain points for intializing Gaussians

# use these two flags to snychronize the updated map and poses back into the SLAM system
feedback_mapping: False
optimize_poses: False

# Strategy for adding / pruning Gaussians
keyframes:
  n_last_frames: 5 # Always optimize the last n frames
  n_rand_frames: 5 # Optimize random global frames on top
  default_batch_size: 5 # Only add 5 frames at once to increase latency when batch_mode is deactivated

  densify_every: 2 # Densify Gaussians every k updates
  prune_every: 1 # Prune Gaussians every k updates
  prune_densify_every: 9 # How often to prune and densify gaussians during optimization
  prune_mode: "abs" # "abs" or "new" How to prune: either absolute visibility or covisibility of new frames
  visibility_th: 2 # Gaussians not visible by visibility_th other frames are pruned
  prune_last: 5 # Prune only Gaussians added during the last k frames (Hint: this needs to be <= n_last_frames)
  abs_visibility_th: 2 # Remove gaussians that are not seen by at least this many other frames

  filter: # Parameter for filtering incoming points from the SLAM system
    mv_count_thresh: 2 # Pixels need to be consistent within bin_thresh distance across these k views
    bin_thresh: 0.05 # Distance between points, this depends on the scene scale, so be careful!
    confidence_thresh: 0.05 # Only take pixels above this confidence (Usually dynamic objects and obvious unuseful pixels like sky are below 0.1) 

  mapping:
    # NOTE when changing the learning rates, you should also change the grad_threshold!
    densify_grad_threshold: 0.0002 # Gradient clipping
    size_threshold: 20 # Max screen size
    opacity_th: 0.01 # Min opacity
    gaussian_extent: 4 # Affects densification, i.e. the larger the more we split gaussians

  refinement:
    densify_grad_threshold: 0.0002 # Gradient clipping
    size_threshold: 10 # Max screen size
    opacity_th: 0.05 # Min opacity
    gaussian_extent: 2  # Affects densification, i.e. the larger the more we split gaussians

opt_params:
  init_lr: 10.0
  position_lr_init: 0.0005 # Default MonoGS: 0.00016
  position_lr_final: 0.00005 # Default MonoGS: 0.000016
  position_lr_delay_mult: 0.01
  position_lr_max_steps: 200
  feature_lr: 0.0025
  opacity_lr: 0.05
  scaling_lr: 0.005 # 0.001
  rotation_lr: 0.001
  percent_dense: 0.01

  # LR for pose optimization
  # Caution: DONT USE A TOO HIGH LR HERE! THIS CAN DESTROY THE MAP!
  cam_rot_delta: 0.0006 # 0.0003
  cam_trans_delta: 0.0002 # 0.0001

loss:
  # Decide which loss terms to use
  with_edge_weight: False # Weight informative pixels with high image gradient higher in loss
  use_ssim: True # Use SSIM on top of L1 loss (Hint: this is very useful for getting smoother surfaces)
  use_depth_smoothness_reg: True # Similarity loss between depth and image gradients

  rgb_boundary_threshold: 0.01 # Pixel information in an image needs to be at least higher than this 
  ### Loss weights
  alpha1: 0.75 # Size of the mapping loss that the rgb takes up, the rest is depth (default: 0.95)
  alpha2: 0.85 # Weight SSIM and L1 loss (default 0.85 is common in monocular depth estimation)
  beta: 5.0 # Regularizer on scale changes of the Gaussians
  beta2: 0.001 # Edge-aware smoothness loss for depth (default 0.001 is common in monocular depth estimation)

# Parameters for transfer SLAM -> Renderer
input:
  sensor_type: 'depth'
  pcd_downsample_init: 8 # This is a constant downsampling factor
  pcd_downsample: 4 # NOTE You normally have up to 20k points per frame
  adaptive_pointsize: False
  point_size: 0.02
  type: 'replica'

batch_mode: False # Only update a constant sized batch of frames (useful to speed things up when we run in parallel)
save_renders: False # Store some rendered images for debugging
# Default vanilla Gaussian Splatting parameters
use_spherical_harmonics: False 
pipeline_params:
  convert_SHs_python: False
  compute_cov3D_python: False