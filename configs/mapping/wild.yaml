defaults:
  - /mapping/base@_here_

warmup: 5 # Wait until tracking gets to this frame
delay: 3 # Delay between tracking and mapping (This should be >= 2, because else )

mcmc:
  cap_max: 300000 # Maximum number of Gaussians in the map
  noise_lr: 1e4 # original: 5e5
  opacity_reg: 0.1
  scale_reg: 0.1

# Online Optimization
online_opt:
  ## Local sliding optimization window
  iters: 100 # Optimization iterations for selected views
  n_last_frames: 10 # Always optimize the last n frames on top of the new ones
  n_rand_frames: 20 # Optimize random global frames on top

  ## Strategy for adding / pruning Gaussians
  prune_every: 2 
  pruning:
    use_covisibility: True
    covisibility:
      # NOTE: Using the absolute visibility check is more wasteful as we need to count the visiblity of each Gaussian!
      # -> Use 'new' for faster performance
      mode: "new" # ["abs", "new"] How to prune: either check for covisible frames everywhere or just in the last n frames
      last: 10 # Prune only Gaussians added during the last k frames (Hint: this needs to be <= n_last_frames)
      visibility_th: 3 # Gaussians not visible by at least this many frames are pruned
      dont_prune_latest: 0 # never prune the most recent k frames (Hint: avoids to always prune and densify needlessly)

    use_floaters: True
    # This is a proxy for density
    floaters:
      search_radius: 0.5 # Search radius for fixed radius nearest neighbor search
      # NOTE this depends on the used depth sensor (monocular models have differences) and scene
      min_nn_distance: 0.001 # Minimum distance to the nearest neighbor for pruning

  # How often to prune and densify gaussians during optimization
  prune_densify_every: 25
  prune_densify_until: 55

  # How to Filter the Tracking Map before feeding into Mapper
  filter: # Parameter for filtering incoming points from the SLAM system
    multiview: True # Only initialize Gaussians that are consistent in multiple views
    mv_count_th: 2 # Pixels need to be consistent within bin_thresh distance across these k views
    bin_th: 0.05 # Distance between points for binning, this depends on the scene scale, so be careful!
    min_disp_th: 0.05  # Relative to distribution, i.e. reject the lowest 1%
    hard_disp_th: 0.1 # Absolute, i.e. reject depth > 5m
    uncertainty: True # Only use very certain points for intializing Gaussians
    conf_th: 0.1 # Only take pixels above this confidence (Usually dynamic objects and obvious unuseful pixels like sky are below 0.1) 

opt_params:
  position_lr_init: 1e-3 # Default MonoGS: 0.00016 (RGB mode has x10)
  position_lr_final: 5e-4 # Default MonoGS: 0.0000016
  position_lr_max_steps: 100 # Default MonoGS: 30000

loss:
  # Decide which terms to use
  supervise_with_prior: False # Use the prior for supervision. If not, then use the current filtered map from SLAM (Hint: this is usually better as metrics are computed on all pixels)
  with_ssim: True # Use SSIM on top of L1 loss (Hint: this is very useful for getting smoother surfaces)
  with_edge_weight: False # Weight informative pixels with high image gradient higher in loss
  with_depth_smoothness: True # Similarity loss between depth and image gradients
  use_ms_ssim: False # Multi-Scale SSIM loss (Hint: This improves mainly PSNR at the cost of slightly worse LPIPS and L1)
  depth_func: l1 # 'l1', 'log_l1', 'l1_huber', 'pearson' (Hint: We achieved best results simply with l1)
  # Weights
  alpha1: 0.8 # Size of the mapping loss that the rgb takes up, the rest is depth (default: 0.95)
  alpha2: 0.2 # Weight SSIM and L1 loss (default 0.85 is common in monocular depth estimation)
  beta1: 6.0 # Regularizer on isotropic scale of the Gaussians (bigger -> more isotropic)
  beta2: 0.001 # Edge-aware smoothness loss for depth (default 0.001 is common in monocular depth estimation)


# Offline Map Refinement for finetuning
refinement:
  iters: 500 # Optimize over this many different batches
  batch_iters: 1 # Optimize each batch this many times
  lr_factor: 0.5 # Change the learning rate for refinement since we already close to convergence
  bs: 40 # Batch size for refinement 
  prune_densify_every: 30 # This uses i) vanilla split and clone from 3DGS and ii) opacity based densificatio# This has to be an uneven number
  densify_until: 300 # Dont densify/prune after this many iterations, ALL gaussians are well optimized

  prune_every: 40
  prune_until: 200
  pruning:
    use_floaters: False
    # This is a proxy for density
    floaters:
      search_radius: 0.5 # Search radius for fixed radius nearest neighbor search
      # NOTE this depends on the used depth sensor (monocular models have differences) and scene
      min_nn_distance: 0.001 # Minimum distance to the nearest neighbor for pruning

  # Sample according to loss order of frames and include non-keyframes if wanted
  sampling:
    use_neighborhood: False # Use neighborhoods around random frames to have more spatial overlap
    neighborhood_size: 5 # How many frames to include in the neighborhood


# Parameters for transfer SLAM -> Renderer
input:
  pcd_downsample_init: 16 # This is a constant downsampling factor
  pcd_downsample: 64 # You ideally have ~5-10k points per frame